[1mdiff --git a/Q-Learning/getSensorValues.h b/Q-Learning/getSensorValues.h[m
[1mdeleted file mode 100644[m
[1mindex fe9e351..0000000[m
[1m--- a/Q-Learning/getSensorValues.h[m
[1m+++ /dev/null[m
[36m@@ -1,205 +0,0 @@[m
[31m-#ifndef GETSENSORVALUES_H_[m
[31m-#define GETSENSORVALUES_H_[m
[31m-[m
[31m-//FOR HALLWAY EXAMPLE[m
[31m-//Walls on either side so if detect nothing and move forward, detect nothing[m
[31m-//detect nothing and turn left once, detect something on left[m
[31m-//detect nothing and turn right once and detect something on right[m
[31m-//detect left and go forward, crash[m
[31m-//detect left and turn left, detect both[m
[31m-//detect left and turn right, detect nothing[m
[31m-//detect right and go forward, crash[m
[31m-//detect right and turn left, detect nothing[m
[31m-//detect right and turn right, detect both[m
[31m-//detect both and go forward, crash[m
[31m-//detect both and turn left, something on right[m
[31m-//detect both and turn right, something on left[m
[31m-[m
[31m-[m
[31m-int getLeft(int prevState, int prevAction) {[m
[31m-  int senseLeft = 999;[m
[31m-  int senseRight = 999;[m
[31m-  bool crash;[m
[31m-  //DETECT NOTHING[m
[31m-  if (prevState == 0 && prevAction == 0) {  //detect nothing go forward leads to detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 0 && prevAction == 1) {  //detect nothing turn right, something on the right[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  if (prevState == 0 && prevAction == 2) {  //detect nothing turn left, something on the left[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT RIGHT[m
[31m-  if (prevState == 1 && prevAction == 0) {  //detect right and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 1 && prevAction == 1) {  //detect right and turn right, detect both[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  if (prevState == 1 && prevAction == 2) {  //detect right and turn left, detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT LEFT[m
[31m-  if (prevState == 2 && prevAction == 0) {  //detect left and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 2 && prevAction == 1) {  //detect left and turn right, detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 2 && prevAction == 2) {  //detect left and turn left, detect both[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT BOTH[m
[31m-  if (prevState == 3 && prevAction == 0) {  //detect both and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 3 && prevAction == 1) {  //detect both and turn right. something on left[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 3 && prevAction == 2) {  //detect  both and turn left, something on right[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  return senseLeft;[m
[31m-}[m
[31m-[m
[31m-int getRight(int prevState, int prevAction) {[m
[31m-  int senseLeft;[m
[31m-  int senseRight;[m
[31m-  bool crash;[m
[31m-  //DETECT NOTHING[m
[31m-  if (prevState == 0 && prevAction == 0) {  //detect nothing go forward leads to detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 0 && prevAction == 1) {  //detect nothing turn right, something on the right[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  if (prevState == 0 && prevAction == 2) {  //detect nothing turn left, something on the left[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT RIGHT[m
[31m-  if (prevState == 1 && prevAction == 0) {  //detect right and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 1 && prevAction == 1) {  //detect right and turn right, detect both[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  if (prevState == 1 && prevAction == 2) {  //detect right and turn left, detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT LEFT[m
[31m-  if (prevState == 2 && prevAction == 0) {  //detect left and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 2 && prevAction == 1) {  //detect left and turn right, detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 2 && prevAction == 2) {  //detect left and turn left, detect both[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT BOTH[m
[31m-  if (prevState == 3 && prevAction == 0) {  //detect both and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 3 && prevAction == 1) {  //detect both and turn right. something on left[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 3 && prevAction == 2) {  //detect  both and turn left, something on right[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  return senseRight;[m
[31m-}[m
[31m-[m
[31m-//GET CRASH[m
[31m-bool getCrash(int prevState, int prevAction) {[m
[31m-  int senseLeft;[m
[31m-  int senseRight;[m
[31m-  bool crash;[m
[31m-  //DETECT NOTHING[m
[31m-  if (prevState == 0 && prevAction == 0) {  //detect nothing go forward leads to detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 0 && prevAction == 1) {  //detect nothing turn right, something on the right[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  if (prevState == 0 && prevAction == 2) {  //detect nothing turn left, something on the left[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT RIGHT[m
[31m-  if (prevState == 1 && prevAction == 0) {  //detect right and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 1 && prevAction == 1) {  //detect right and turn right, detect both[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  if (prevState == 1 && prevAction == 2) {  //detect right and turn left, detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT LEFT[m
[31m-  if (prevState == 2 && prevAction == 0) {  //detect left and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 2 && prevAction == 1) {  //detect left and turn right, detect nothing[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 2 && prevAction == 2) {  //detect left and turn left, detect both[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-[m
[31m-  //DETECT BOTH[m
[31m-  if (prevState == 3 && prevAction == 0) {  //detect both and go forward, crash[m
[31m-    crash = true;[m
[31m-  }[m
[31m-  if (prevState == 3 && prevAction == 1) {  //detect both and turn right. something on left[m
[31m-    senseLeft = 1;[m
[31m-    senseRight = 0;[m
[31m-  }[m
[31m-  if (prevState == 3 && prevAction == 2) {  //detect  both and turn left, something on right[m
[31m-    senseLeft = 0;[m
[31m-    senseRight = 1;[m
[31m-  }[m
[31m-  return crash;[m
[31m-}[m
[31m-[m
[31m-[m
[31m-[m
[31m-#endif /* GETSENSORVALUES_H_ */[m
[31m-/* Q TABLE[m
[31m- //Q[row][column][m
[31m- //rows are states, columns are actions[m
[31m- //States: 0 detect nothing, 1 detect right, 2 detect left, 3 detect both (front)[m
[31m- //Actions: 0 move forward, 1 turn right in place, 2 turn left in place[m
[31m- */[m
[1mdiff --git a/Q-Learning/main.cpp b/Q-Learning/main.cpp[m
[1mdeleted file mode 100644[m
[1mindex 464b058..0000000[m
[1m--- a/Q-Learning/main.cpp[m
[1m+++ /dev/null[m
[36m@@ -1,228 +0,0 @@[m
[31m-#include <iostream>[m
[31m-#include <stdlib.h>[m
[31m-[m
[31m-#include "getSensorValues.h"[m
[31m-using std::cout;[m
[31m-using std::endl;[m
[31m-[m
[31m-//define class[m
[31m-class robot {[m
[31m- public:[m
[31m-  int state;[m
[31m-  int prevState;[m
[31m-  int action;[m
[31m-  int prevAction;[m
[31m-  int reward;[m
[31m-  int Q[4][3] = { };[m
[31m-[m
[31m-  double alpha = .5;[m
[31m-  double gamma = .8;[m
[31m-[m
[31m-  int findState(int senseOne, int senseTwo);  //determine state based on sensors[m
[31m-  int decideAction(int state);  //determine action based on state[m
[31m-  int assignReward(int prevAction, bool crash);  //assign rewards based on what action was taken[m
[31m-  int maxFuture(int state);[m
[31m-  void updateTable(int prevAction, int prevState, bool crash, int state);[m
[31m-};[m
[31m-[m
[31m-[m
[31m-/* Q TABLE[m
[31m-//Q[row][column][m
[31m-//rows are states, columns are actions[m
[31m-//States: 0 detect nothin, 1 detect right, 2 detect left, 3 detect both (front)[m
[31m-//Actions: 0 move forward, 1 turn left in place, 2 turn right in place[m
[31m- */[m
[31m-//int Q[4][3] = { };  //initial values are all zero[m
[31m-[m
[31m-[m
[31m-//DETERMINE STATE[m
[31m-int robot::findState(int left, int right) {[m
[31m-  int state = 0;[m
[31m-  if (left == 0 && right == 0) {[m
[31m-    state = 0;[m
[31m-  }[m
[31m-  if (left == 0 && right == 1) {[m
[31m-    state = 1;[m
[31m-  }[m
[31m-  if (left == 1 && right == 0) {[m
[31m-    state = 2;[m
[31m-  }[m
[31m-  if (left == 1 && right == 1) {[m
[31m-    state = 3;[m
[31m-  }[m
[31m-  return state;[m
[31m-}[m
[31m-[m
[31m-//DECIDE ACTION[m
[31m-int robot::decideAction(int state) {[m
[31m-  int action;[m
[31m-  int Rand = rand() % 100;[m
[31m-[m
[31m-  //15 percent chance of choosing a random action. Want random action sometimes to explore new possibilities/possible better action[m
[31m-  if (Rand > 65) {[m
[31m-    int randAction = rand() % 3;  //random number between 0 and 2[m
[31m-[m
[31m-    action = randAction;[m
[31m-    cout << "Random action " << action << " was chosen" << endl;  //print we did a random action[m
[31m-  }[m
[31m-  //Use Q table to choose highest rated action for current state, do this most of the time[m
[31m-  else {[m
[31m-    int bestAction;  //initiate best action var[m
[31m-    int bestQ = -100000;  //initiate best Q value, this corresponds to a state action pair value[m
[31m-    //cout << "Best Q: " << bestQ << endl;[m
[31m-    for (int i = 0; i < 3; i++) {  //cycle through every action for current state[m
[31m-      if (Q[state][i] > bestQ) {  //if state action pair Q value is greater than current best value[m
[31m-        bestQ = Q[state][i];  //set new highest Q value[m
[31m-        bestAction = i;  //set new best action[m
[31m-[m
[31m-      }[m
[31m-    }[m
[31m-    //print we used Q table, what we did[m
[31m-    cout << "Q table used to decide action:" << endl;[m
[31m-    cout << "For state " << state << ", action " << bestAction[m
[31m-         << " was chosen." << endl << endl;[m
[31m-    action = bestAction;[m
[31m-  }[m
[31m-  return action;  //return chosen action[m
[31m-}[m
[31m-[m
[31m-//ASSIGN REWARD[m
[31m-int robot::assignReward(int prevAction, bool crash) {[m
[31m-  int reward;[m
[31m-  if (prevAction == 0) {  //if moved forward reward since we want to explore[m
[31m-    reward = 10;[m
[31m-  }[m
[31m-  if (prevAction == 1 || prevAction == 2) {  //if turn thats neutral, not bad but not exploring[m
[31m-    reward = 0;[m
[31m-  }[m
[31m-  if (crash)  //if crashed give big negative reward[m
[31m-    reward = -100;[m
[31m-  //cout << "Reward " << reward << endl;[m
[31m-  return reward;[m
[31m-}[m
[31m-[m
[31m-//FIND MAX FUTURE VALUE[m
[31m-//Need the max future value to update the Q table[m
[31m-int robot::maxFuture(int state) {[m
[31m-  int currentMax = -100000;  //initiate var to keep track of max[m
[31m-[m
[31m-  for (int i = 0; i != 3; i++) {  //cycle through every action[m
[31m-    if (Q[state][i] > currentMax)  //if state action pair Q value greater than current Q value[m
[31m-      currentMax = Q[state][i];  //set new max Q value[m
[31m-  }[m
[31m-[m
[31m-  return currentMax;[m
[31m-}[m
[31m-[m
[31m-//UPDATE Q TABLE[m
[31m-void robot::updateTable(int prevAction, int prevState, bool crash, int state) {[m
[31m-  double reward = assignReward(prevAction, crash);  //get the reward based on previous action and if crash[m
[31m-//  cout << "For Q value " << Q[prevState][prevAction] << endl;[m
[31m-[m
[31m-  //Update Q value using equation. Based on old Q value, reward, max Q value of new state, and constants alpha, gamma[m
[31m-  if (crash == true) {  //if crash, the new state doesn't count, it crashed[m
[31m-    Q[prevState][prevAction] = Q[prevState][prevAction] + alpha * (reward)[m
[31m-        - Q[prevState][prevAction];[m
[31m-  }[m
[31m-[m
[31m-  else {[m
[31m-  Q[prevState][prevAction] =[m
[31m-      Q[prevState][prevAction][m
[31m-          + alpha[m
[31m-          * (reward + (gamma * maxFuture(state))[m
[31m-                  - Q[prevState][prevAction]);[m
[31m-  cout << "Reward  " << reward << endl;[m
[31m-[m
[31m-  }[m
[31m-}[m
[31m-[m
[31m-int main() {[m
[31m-  robot Test;      //initiate test var[m
[31m-  int firstRun = 0;  //Can't update Q table on first run, no previous data to go off of[m
[31m-  int prevState;[m
[31m-  int prevAction;[m
[31m-  //initiate sensors[m
[31m-  int left = 0;[m
[31m-  int right = 0;[m
[31m-  bool crash = false;  //initiate not crashing[m
[31m-[m
[31m-[m
[31m-[m
[31m-[m
[31m-  for (int a = 0; a < 1000; a++) {  //number of iterations to train for[m
[31m-    /* int sensorOneRand = rand() % 100 + 1;  //generate random input values for sensor[m
[31m-    int sensorTwoRand = rand() % 100 + 1;[m
[31m-[m
[31m-    int one = 0;  //initiate sensor values for 0, detect nothing[m
[31m-    int two = 0;[m
[31m-    if (sensorOneRand > 70)[m
[31m-      one = 1;[m
[31m-    if (sensorTwoRand > 70)[m
[31m-     two = 1;*/[m
[31m-    [m
[31m-    //If the first run has finished use getLeft and getRight to get sensor values[m
[31m-    //Can't use these on first run since they require a previous state and previous action[m
[31m-    if (firstRun > 0) {[m
[31m-      //Get new sensor values based on what previous state and previous action was[m
[31m-      //This is for hallway example, see getSensorValues for details[m
[31m-      left = getLeft(prevState, prevAction);[m
[31m-      right = getRight(prevState, prevAction);[m
[31m-    }[m
[31m-[m
[31m-    //print the sensor values[m
[31m-    cout << "sensorLeft: " << left << endl;[m
[31m-    cout << "sensorRight: " << right << endl;[m
[31m-[m
[31m-    //Determine state based on left and right sensors[m
[31m-    int state = Test.findState(left, right);  //set state with sensor vals[m
[31m-    cout << "state: " << state << endl;[m
[31m-[m
[31m-    //CANT UPDATE ON FIRST RUN. IF AFTER THAT UPDATE[m
[31m-    if (firstRun > 0) {[m
[31m-      if ((prevState == 3 && prevAction == 0)[m
[31m-          || (prevState == 1 && prevAction == 0)[m
[31m-          || (prevState == 2 && prevAction == 0)) {  //if something detected and move forward, crash[m
[31m-        crash = true;[m
[31m-      }[m
[31m-[m
[31m-      //Update the Q Table based on prevstate, prevaction , and current state[m
[31m-      cout << endl;[m
[31m-      cout << "Previous Action: " << prevAction << endl;[m
[31m-      cout << "Previous state: " << prevState << endl;[m
[31m-      cout << "Current state: " << state << endl;[m
[31m-      Test.updateTable(prevAction, prevState, crash, state);  //update the Q table[m
[31m-[m
[31m-    }[m
[31m-[m
[31m-    //Decide action based on current state. Picks either random action or uses table to decide[m
[31m-    int action = Test.decideAction(state);    //decide action based on state[m
[31m-[m
[31m-[m
[31m-[m
[31m-    prevState = state;    //set prevstate = state before next iteration[m
[31m-    prevAction = action;    //same[m
[31m-[m
[31m-    firstRun = 1;  //Now that first run complete there are previous values, so we can update the table[m
[31m-[m
[31m-    //if crash reset  robot to first position, keep Q table though[m
[31m-    if (crash == true) {[m
[31m-      cout << "CRASH took place previous stage" << endl;[m
[31m-      crash = false;[m
[31m-      firstRun = 0;    //basically start over if there is a crash[m
[31m-      left = 0;    //give initial sensor values again[m
[31m-      right = 0;[m
[31m-    }[m
[31m-[m
[31m-[m
[31m-[m
[31m-//PRINT Q TABLE[m
[31m-  cout << Test.Q[0][0] << " " << Test.Q[0][1] << " " << Test.Q[0][2] << endl;[m
[31m-  cout << Test.Q[1][0] << " " << Test.Q[1][1] << " " << Test.Q[1][2] << endl;[m
[31m-  cout << Test.Q[2][0] << " " << Test.Q[2][1] << " " << Test.Q[2][2] << endl;[m
[31m-    cout << Test.Q[3][0] << " " << Test.Q[3][1] << " " << Test.Q[3][2] << endl;[m
[31m-    cout << endl;[m
[31m-[m
[31m-[m
[31m-  }[m
[31m-  return 0;[m
[31m-}[m
